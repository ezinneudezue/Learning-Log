# 2025-11-30 – Today I Learned

#Structured outputs are more reliable than you think—if you ask right.
When you need JSON from an LLM, don't just say "return JSON." Instead, give the model a concrete schema in your prompt and ask it to fill in the values.   

Something like:  
Respond with exactly this JSON structure, filling in the values:
>{  
>  "sentiment": "positive" | "negative" | "neutral",  
>  "confidence": <float 0-1>,  
>  "key_phrases": [<list of strings>]  
}

This works dramatically better than "return your analysis as JSON" because you're reducing the model's degrees of freedom. It's not deciding what to output, just filling in blanks—a much easier task that fails less often.  
Bonus: most API providers now offer native JSON mode or structured output features that constrain the model's token generation to valid JSON, making malformed output nearly impossible.


## Here's an example
Task: Extract contact info from a message.
User message:
Hey, I'm Sarah Chen. You can reach me at sarah.chen@example.com or call 555-0142.
Schema you provide in your prompt:
json{
  "name": "<string>",
  "email": "<string or null>",
  "phone": "<string or null>"
}
```
Full prompt:**

Extract the contact information from the following message.

Respond with exactly this JSON structure, filling in the values:
{
  "name": "<string>",
  "email": "<string or null>",
  "phone": "<string or null>"
}

Message: Hey, I'm Sarah Chen. You can reach me at sarah.chen@example.com or call 555-0142.
```
   
Expected output:   
>json
>{  
>  "name": "Sarah Chen",  
>  "email": "sarah.chen@example.com",  
>  "phone": "555-0142"  
>}  
